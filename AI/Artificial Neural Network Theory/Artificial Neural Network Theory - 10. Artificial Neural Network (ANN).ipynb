{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0a8939f",
   "metadata": {},
   "source": [
    "- History of ANN\n",
    "    - McCulloch-Pitts Model (=Threshoold Logic Model)\n",
    "      - Be proposed by Warren McCulloch and Walter Pitts in 1943\n",
    "      - Basic ideas:\n",
    "        - A neuron is represented as a binary threshold unit\n",
    "        - The binary threshold unit combines weighted inputes\n",
    "        - Output is based on whether sum exceeds a threshold\n",
    "    - Perceptron Model\n",
    "      - Be proposed by Frank Rosenblatt in 1950s\n",
    "      - Basic ideas:\n",
    "        - Be consist of a single layer of artificial neurons\n",
    "        - Each neuron takes weighted input data -> aggregate weighted inputs\n",
    "        - Output is based on activation functions\n",
    "    - Backpropagation\n",
    "      - Be proposed in 1980s\n",
    "      - Basic ideas:\n",
    "        - An algorithm to train nueral networks\n",
    "        - Adjust weights by propagating errors from the output layers back to the prevous layers\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38374655",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e971628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8f9efe",
   "metadata": {},
   "source": [
    "### Define an ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38afa89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a structure of ANN\n",
    "class ANN(nn.Module):\n",
    "    \n",
    "    # Initialize the class\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # Initialize the class from the superclass\n",
    "        super(ANN, self).__init__() \n",
    "        \n",
    "        # Input layer -> Hidden Layer (Linear Transformation)\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        # Set an activation function for hidden layers: Using 'ReLU'\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Hidden layer -> Output layer\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    \n",
    "    # Define the forward method\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Pass `x`: Input layer -> Hidden layer\n",
    "        out = self.fc1(x)\n",
    "        \n",
    "        # Apply ReLU as an activation function\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        # Pass the result applied ReLU: Hidden layer -> Output layer\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2df8a2e",
   "metadata": {},
   "source": [
    "### Run the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "672bc382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 10], Loss: 2.3223\n",
      "Epoch [2 / 10], Loss: 1.6100\n",
      "Epoch [3 / 10], Loss: 1.0857\n",
      "Epoch [4 / 10], Loss: 0.6569\n",
      "Epoch [5 / 10], Loss: 0.3764\n",
      "Epoch [6 / 10], Loss: 0.2269\n",
      "Epoch [7 / 10], Loss: 0.1502\n",
      "Epoch [8 / 10], Loss: 0.1081\n",
      "Epoch [9 / 10], Loss: 0.0828\n",
      "Epoch [10 / 10], Loss: 0.0663\n"
     ]
    }
   ],
   "source": [
    "# Set parameters for nodes\n",
    "input_size = 784\n",
    "hidden_size = 256\n",
    "output_size = 10\n",
    "\n",
    "# Set the ANN model\n",
    "model = ANN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Set a Loss Function: Cross Entropy \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set learning rates and optimizer\n",
    "learning_rate = 0.5\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set learning data with labels\n",
    "inputs = torch.randn(100, input_size)  # size: 100 * 784\n",
    "labels = torch.randint(0,           # Generate random int values from '0' to 'output_size(=10)'\n",
    "                       output_size, \n",
    "                       (100,))      # Dimensions: (100, )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Fit model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Forward propagation\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Calculate dissimilarity between the predicted and actual values\n",
    "    loss = criterion(outputs,  # Predicted values\n",
    "                     labels)   # Actual values\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Initialize optimizer with '0'\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Backprogation\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update parameters to reduce loss\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Display loss\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(f'Epoch [{epoch+1} / {num_epochs}], Loss: {loss.item():.4f}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
